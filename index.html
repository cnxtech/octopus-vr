<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8">
    <title>Hello, World! - A-Frame</title>
    <meta name="description" content="Hello, World! - A-Frame">
    <script src="https://aframe.io/releases/0.7.0/aframe.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/annyang/2.5.0/annyang.min.js"></script> 
  </head>
  <body>
    <script>
      AFRAME.registerComponent('text-box', {
        init: function() {
          console.log('in init text-box');
        },

        toggle: function() {
          const el = this.el;
          console.log('hide');
          el.setAttribute('visible', !el.getAttribute('visible'));
        }
      });
      AFRAME.registerComponent('speech-recognition', {
        init: function () {
          //console.log("in annyang-speech-recognition init");
          this.play()
        },
        showPerson: function(name) {
          console.log(`show name ${name}`)
        },
        showCurrentSpeaker: function() {
          console.log('show current speaker')
        },
        play: function() {
          if (!annyang) { return }

          let commands = {
            'who is talking': this.showCurrentSpeaker,
            'who is speaking': this.showCurrentSpeaker,
            'who is *name': this.showPerson
          }

          annyang.debug()
          annyang.addCommands(commands)
          annyang.setLanguage('en')


          // var speechCommandSystem = document.querySelector('a-scene').systems['speech-command'];
          // var commands = {};
          // var commandsMap = {};
          // for (var i = 0; i < speechCommandSystem.entities.length; i++) {
          //     var speechCommand = speechCommandSystem.entities[i];
          //     commandsMap[speechCommand.data.command] = speechCommand;
          //     // note: function empty here because real work is done in the resultMatch callback below
          //     commands[speechCommand.data.command] = function() { };
          // }
          // annyang.addCommands(commands);

          // annyang.addCallback('resultMatch', function(userSaid, commandText, phrases) {
          //     //console.log("commandText: "+commandText); // sample output: 'hello (there)'
          //     var speechCommand = commandsMap[commandText];
          //     speechCommand.executeCommand();
          // });
          // Start listening. You can call this here, or attach this call to an event, button, etc.
          console.log('annyang starting')
          annyang.start();
        }
      });
    </script>
    <a-scene>
      <a-videosphere src="#video" rotation="0 180 0"></a-videosphere>
      <a-entity id="annyang" speech-recognition></a-entity>
      <a-assets>
        <video id="rhonyc" 
               preload="auto" 
               src="./../assets/rhonyc_801.mp4#t=50"
               autoplay loop crossorigin="anonymous" position="2 2 2">
        </video>
      </a-assets>
      <a-box text-box
             id="textBox"
             material="color: #555555; transparent: true; opacity: 0.9" 
             depth="0.1" height="1" width="1" 
             position="4 2 -5">
      </a-box>
      <a-entity id="video"
                material="shader: flat; src: #rhonyc"
                geometry="primitive: plane; width: 360; height: 240;"
                position="0 0 -250"
                rotation="0 0 0">
      </a-entity>
    </a-scene>
  </body>
</html>
